# Classification Automatique de Mammographies MIAS avec Deep Learning

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.x](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Projet d'Intelligence Artificielle pour la d√©tection et classification d'anomalies mammographiques utilisant des r√©seaux de neurones convolutifs (CNN)**

## Table des Mati√®res

- [Objectif du Projet](#-objectif-du-projet)
- [Dataset MIAS](#-dataset-mias)
- [Architecture](#Ô∏è-architecture)
- [Installation Rapide](#-installation-rapide)
- [Utilisation](#-utilisation)
- [R√©sultats](#-r√©sultats)
- [Documentation](#-documentation)
- [Contribution](#-contribution)
- [Licence](#-licence)

## Objectif du Projet

Ce projet d√©veloppe un syst√®me d'aide au diagnostic pour la **classification automatique d'anomalies mammographiques** en utilisant le c√©l√®bre dataset MIAS (Mammographic Image Analysis Society).

### Probl√©matique

- **D√©tection pr√©coce** : Am√©liorer la d√©tection du cancer du sein
- **Assistance m√©dicale** : Aider les radiologues dans l'interpr√©tation des mammographies
- **Standardisation** : R√©duire la variabilit√© inter-observateur

### Objectifs Techniques

- Classifier 7 types d'anomalies mammographiques
- Comparer 3 architectures CNN (Baseline, Optimis√©, ResNet50)
- Atteindre une pr√©cision >60% sur le dataset de test
- Fournir des m√©triques cliniquement pertinentes

## Dataset MIAS

### Composition
- **330 mammographies** digitalis√©es en haute r√©solution
- **7 classes d'anomalies** : NORM, CALC, CIRC, ARCH, SPIC, MISC, ASYM
- **Annotations expertes** avec coordonn√©es et rayons des l√©sions

### Classes d'Anomalies

| Classe   | Description                 | Nombre d'√©chantillons |
|----------|-----------------------------|-----------------------|
| **NORM** | Images normales             | 207 (62.7%)           |
| **CALC** | Calcifications              | 30 (9.1%)             |
| **CIRC** | Masses circulaires          | 25 (7.6%)             |
| **ARCH** | Distorsions architecturales | 19 (5.8%)             |
| **SPIC** | Masses spicul√©es            | 19 (5.8%)             |
| **MISC** | Anomalies diverses          | 15 (4.5%)             |
| **ASYM** | Asym√©tries                  | 15 (4.5%)             |

## Architecture

### Mod√®les D√©velopp√©s

1. **CNN Baseline** : Architecture simple de r√©f√©rence
2. **CNN Optimis√©** : Am√©lioration avec dropout et couches suppl√©mentaires
3. **ResNet50** : Transfer learning avec architecture pr√©-entra√Æn√©e

### Pipeline de Traitement

```mermaid
flowchart LR
    A[Images MIAS] --> B[Pr√©processing]
    B --> C[Augmentation]
    C --> D[Division Train/Test]
    D --> E[Entra√Ænement CNN]
    E --> F[√âvaluation]
    F --> G[Rapport Final]
```

## ‚ö° Installation Rapide

### Pr√©requis

- Python 3.8+
- GPU recommand√© (CUDA compatible)
- 8GB RAM minimum

### üõ†Ô∏è Installation

```bash
# Cloner le repository
git clone https://github.com/username/breast_cancer_nrb.git
cd breast_cancer_nrb

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt

# T√©l√©charger le dataset MIAS (si n√©cessaire)
python scripts/download_data.py
```

### D√©pendances Principales

```txt
tensorflow>=2.8.0
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.5.0
scikit-learn>=1.0.0
Pillow>=8.3.0
jupyter>=1.0.0
seaborn>=0.11.0
```

## Utilisation

### Notebooks Jupyter (Approche P√©dagogique)

```bash
# Lancer Jupyter Lab
jupyter lab

# Suivre les notebooks dans l'ordre :
# 1. 01_data_exploration.ipynb
# 2. 02_mvp_baseline.ipynb  
# 3. 03_model_comparison.ipynb
# 4. 04_results_analysis.ipynb
# 5. 05_report_generation.ipynb
```

### Scripts Python (Approche Production)

```bash
# Entra√Æner tous les mod√®les
python scripts/train_models.py

# √âvaluer les performances
python scripts/evaluate_models.py

# G√©n√©rer le rapport final
python scripts/generate_report.py
```

### Utilisation Avanc√©e

```python
from src.models.cnn_models import build_optimized_cnn
from src.data.data_loader import load_mias_data

# Charger les donn√©es
X_train, X_test, y_train, y_test = load_mias_data()

# Cr√©er et entra√Æner un mod√®le
model = build_optimized_cnn(input_shape=(128, 128, 1), num_classes=7)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
model.fit(X_train, y_train, validation_data=(X_test, y_test))
```

## R√©sultats

### Performances des Mod√®les

| Mod√®le           | Accuracy | Precision | Recall  | F1-Score |
|------------------|----------|-----------|---------|----------|
| **CNN Baseline** | 60.6%    | 38.2%     | 60.6%   | 46.9%.   |
| **CNN Optimis√©** | 57.6%.   | 36.1%     | 57.6%.  | 44.5%    |
| **ResNet50**     | 9.1%     | 0.8%      | 9.1%    | 1.5%     |

### Insights Cl√©s

- **Mod√®le Baseline** : Meilleure performance globale
- **D√©s√©quilibre des classes** : Impact majeur sur les performances
- **Classes minoritaires** : Difficiles √† d√©tecter (ARCH, SPIC, MISC)
- **Potentiel d'am√©lioration** : Techniques d'√©quilibrage n√©cessaires

### D√©fis Identifi√©s

1. **D√©s√©quilibre s√©v√®re** : 62.7% d'images normales
2. **Dataset limit√©** : 330 √©chantillons pour 7 classes
3. **Complexit√© m√©dicale** : Subtilit√© des anomalies

## Documentation

### Notebooks D√©taill√©s

- **[01_data_exploration.ipynb](notebooks/01_data_exploration.ipynb)** : Analyse exploratoire compl√®te
- **[02_mvp_baseline.ipynb](notebooks/02_mvp_baseline.ipynb)** : Mod√®le de r√©f√©rence
- **[03_model_comparison.ipynb](notebooks/03_model_comparison.ipynb)** : Comparaison d'architectures
- **[04_results_analysis.ipynb](notebooks/04_results_analysis.ipynb)** : Analyse approfondie des r√©sultats
- **[05_report_generation.ipynb](notebooks/05_report_generation.ipynb)** : Rapport final automatis√©

### Documentation Technique

- **[M√©thodologie](docs/methodology.md)** : Approche scientifique d√©taill√©e
- **[Architectures](docs/model_architecture.md)** : Sp√©cifications techniques des mod√®les
- **[Interpr√©tation](docs/results_interpretation.md)** : Analyse clinique des r√©sultats

## Contribution

### D√©veloppement

```bash
# Fork le projet
git clone https://github.com/votre-username/breast_cancer_nrb.git

# Cr√©er une branche feature
git checkout -b feature/nouvelle-fonctionnalite

# Commiter vos changements
git commit -m "Add: nouvelle fonctionnalit√©"

# Pousser vers la branche
git push origin feature/nouvelle-fonctionnalite

# Ouvrir une Pull Request
```

### Tests

```bash
# Lancer les tests unitaires
python -m pytest tests/

# V√©rifier la couverture
python -m pytest --cov=src tests/
```

### Standards de Code

- **PEP 8** : Respecter les conventions Python
- **Type Hints** : Utiliser les annotations de type
- **Docstrings** : Documenter toutes les fonctions
- **Tests** : Couvrir les nouvelles fonctionnalit√©s

## Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

## Remerciements

- **MIAS Database** : Mammographic Image Analysis Society
- **BeCode** : Formation en Intelligence Artificielle
- **Communaut√© Open Source** : TensorFlow, Scikit-learn, Matplotlib

---

## R√©f√©rences

1. Suckling, J. et al. (1994). "The mammographic image analysis society digital mammogram database"
2. LeCun, Y. et al. (1989). "Backpropagation applied to handwritten zip code recognition"
3. He, K. et al. (2016). "Deep residual learning for image recognition"

---

*Merci √† NRB et Becode pour m'avoir donn√© l'opportunit√© de travailler sur ce use case :-)*


## ‚ö†Ô∏è Note Importante - Fichiers Volumineux

### Fichiers Exclus du Repository

En raison de la **taille des fichiers** et des limitations de GitHub, les √©l√©ments suivants ne sont **PAS inclus** dans ce repository :

#### **Donn√©es (data/)**
- **Images MIAS** : `data/raw/MIAS/` (~500MB)
- **Donn√©es pr√©process√©es** : `data/processed/*.npy` (~200MB)
- **M√©tadonn√©es** : `data/*.csv`

#### **Mod√®les Entra√Æn√©s (models/)**
- **Mod√®les sauvegard√©s** : `*.keras` (~50-100MB chacun)
- **Historiques d'entra√Ænement** : `*.pkl` (~10-20MB chacun)
- **Checkpoints** : `*.ckpt`

#### **R√©sultats (results/)**
- **Graphiques g√©n√©r√©s** : `results/figures/*.png`
- **Rapports** : `results/reports/`
- **M√©triques** : `results/metrics/`

### Comment Obtenir les Donn√©es

#### **Option 1 : Dataset MIAS Original**
```bash
# T√©l√©charger depuis le site officiel MIAS
wget http://peipa.essex.ac.uk/info/mias.html
# Extraire dans data/raw/MIAS/
```

#### **Option 2 : Script Automatique**
```bash
# Ex√©cuter le script de t√©l√©chargement
python scripts/download_data.py
```

#### **Option 3 : Kaggle**
```bash
# Via Kaggle CLI
kaggle datasets download -d kmader/mias-mammography
```

### G√©n√©ration des Fichiers Manquants

Une fois le dataset t√©l√©charg√©, ex√©cutez les notebooks dans l'ordre pour r√©g√©n√©rer :

1. **Donn√©es pr√©process√©es** : `01_data_exploration.ipynb`
2. **Mod√®les entra√Æn√©s** : `02_mvp_baseline.ipynb` ‚Üí `03_model_comparison.ipynb`
3. **R√©sultats et graphiques** : `04_results_analysis.ipynb` ‚Üí `05_report_generation.ipynb`

### Taille Approximative des Fichiers

| Cat√©gorie                 | Taille Totale | Description                                     |
|---------------------------|---------------|-------------------------------------------------|
| **Images MIAS**           | ~500 MB       | 330 mammographies en PNG                        |
| **Donn√©es pr√©process√©es** | ~200 MB       | Arrays NumPy (X_train, X_test, y_train, y_test) |
| **Mod√®les entra√Æn√©s**     | ~150 MB       | 3 mod√®les CNN (.keras)                          |
| **Historiques**.          | ~50 MB        | Historiques d'entra√Ænement (.pkl)               |
| **R√©sultats**             | ~20 MB        | Graphiques et rapports g√©n√©r√©s                  |
| **TOTAL**                 | **~920 MB*.   | Trop volumineux pour GitHub gratuit             |

### Alternative : Git LFS

Pour les projets futurs, consid√©rez **Git Large File Storage (Git LFS)** :

```bash
# Installer Git LFS
git lfs install

# Tracker les gros fichiers
git lfs track "*.keras"
git lfs track "*.npy"
git lfs track "data/**"

# Commit normalement
git add .gitattributes
git commit -m "Add Git LFS tracking"
```

---

*Cette approche maintient un repository l√©ger tout en pr√©servant la reproductibilit√© du projet*